{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "The deliverable for Milestone 3 is a Jupyter Notebook (preferably hosted on GitHub) showing a workflow to set up FCN and U-Net models for training using NWPU-RESISC45 lake images and corresponding labels. This will mostly test your understanding of the generic workflow of setting up multiple models for sequential training, in order to evaluate and compare model outputs and ultimately decide which model is best for the task, as well as how to implement custom conditional random fields for refining labels and segmentations in Milestones 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:06:39.120323Z",
     "start_time": "2020-07-10T18:06:38.250434Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import json, os, glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, Conv2DTranspose, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:06:39.161910Z",
     "start_time": "2020-07-10T18:06:39.121284Z"
    }
   },
   "outputs": [],
   "source": [
    "def unzip(f):\n",
    "    \"\"\"\n",
    "    f = file to be unzipped\n",
    "    \"\"\"    \n",
    "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare sentinel 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:07:05.793360Z",
     "start_time": "2020-07-10T18:06:39.162967Z"
    }
   },
   "outputs": [],
   "source": [
    "#imagery\n",
    "file_id = '1iMfIjr_ul49Ghs2ewazjCt8HMPfhY47h'\n",
    "destination = 's2cloudless_imagery.zip'\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "\n",
    "#labels\n",
    "file_id = '1c7MpwKVejoUuW9F2UaF_vps8Vq2RZRfR'\n",
    "destination = 's2cloudless_label_imagery.zip'\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "# unzip\n",
    "unzip('s2cloudless_imagery.zip')\n",
    "unzip('s2cloudless_label_imagery.zip')\n",
    "\n",
    "\n",
    "# remove zip files\n",
    "os.remove('s2cloudless_imagery.zip')\n",
    "os.remove('s2cloudless_label_imagery.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:07:05.807714Z",
     "start_time": "2020-07-10T18:07:05.794214Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    fill_mode = \"constant\", cval=0.0)\n",
    "\n",
    "img_generator = train_datagen.flow_from_directory(\n",
    "        's2cloudless_imagery',\n",
    "        target_size=(512, 512),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None, seed=111, shuffle=False)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    fill_mode = \"constant\", cval=0.0)\n",
    "\n",
    "mask_generator = test_datagen.flow_from_directory(\n",
    "        's2cloudless_label_imagery',\n",
    "        target_size=(512, 512),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None, seed=111, shuffle=False)\n",
    "\n",
    "train_generator = (pair for pair in zip(img_generator, mask_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:46:44.615864Z",
     "start_time": "2020-07-10T18:46:39.955436Z"
    }
   },
   "outputs": [],
   "source": [
    "img_batch, mask_batch = next(train_generator)\n",
    "\n",
    "def get_pair(i):\n",
    "    img = img_batch[i].astype('uint8')/255\n",
    "    msk = np.max(mask_batch[i], axis=2)/255\n",
    "    msk[msk>=.5]  = 1\n",
    "    msk[msk<.5] = 0\n",
    "    msk = np.stack((msk,)*3, axis=-1)\n",
    "    return np.concatenate([img, msk], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:46:44.937552Z",
     "start_time": "2020-07-10T18:46:44.647428Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.axis('off')\n",
    "print(f\"{get_pair(0).shape}\")\n",
    "plt.imshow(get_pair(0))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(get_pair(11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:07:11.226945Z",
     "start_time": "2020-07-10T18:07:10.481456Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input((1216, 1920, 3))\n",
    "_tensor = inputs\n",
    "  \n",
    "#down sampling \n",
    "f = 8 #initially, use an 8-pixel kernel for the convolutional filter\n",
    "layers = []\n",
    "\n",
    "#cycle through 6 iterations, each time reusing '_tensor' \n",
    "#on each iteration ...\n",
    "#pass through 2 convolutional blocks, append to the 'layers' output list\n",
    "#then apply max pooling, and double the filter size for the next iteration\n",
    "for i in range(0, 6):\n",
    "   _tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "   _tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "   layers.append(_tensor)\n",
    "   _tensor = MaxPooling2D() (_tensor)\n",
    "   f = f*2\n",
    "   print(_tensor.shape)\n",
    "\n",
    "\n",
    "#bottleneck \n",
    "ff2 = 64 ##use an 64-pixel kernel for the convolutional filter  \n",
    "j = len(layers) - 1\n",
    "_tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "_tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "_tensor = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_tensor)\n",
    "# use concatenate to merge feature maps\n",
    "_tensor = Concatenate(axis=3)([_tensor, layers[j]])\n",
    "j = j -1 \n",
    "print(_tensor.shape)\n",
    "\n",
    "#upsampling \n",
    "for i in range(0, 5):\n",
    "    ff2 = ff2//2\n",
    "    f = f // 2 \n",
    "    _tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "    _tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "    _tensor = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_tensor)\n",
    "    _tensor = Concatenate(axis=3)([_tensor, layers[j]])\n",
    "    print(f\"j@decoder: {j}\")\n",
    "    print(_tensor.shape)\n",
    "    j = j - 1\n",
    "\n",
    "_tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)\n",
    "_tensor = Conv2D(f, 3, activation='relu', padding='same') (_tensor)  \n",
    "_tensor.shape\n",
    "print(_tensor.shape)\n",
    "\n",
    "outputs = Conv2D(3, 1, activation='sigmoid') (_tensor)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:07:11.239601Z",
     "start_time": "2020-07-10T18:07:11.228120Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
